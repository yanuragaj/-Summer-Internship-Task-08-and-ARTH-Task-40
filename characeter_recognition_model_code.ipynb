{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "733a3787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a80e65ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 864 images belonging to 36 classes.\n",
      "Found 216 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, width_shift_range=0.1, height_shift_range=0.1)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(28,28),  # all images will be resized to 28x28\n",
    "        batch_size=1,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        'data/val',  # this is the target directory\n",
    "        target_size=(28,28),  # all images will be resized to 28x28        batch_size=1,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f912027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Dropout, Conv2D\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9bde47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanur\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (24,24), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(36, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.00001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85251cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanur\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "863/864 [============================>.] - ETA: 0s - loss: 3.5183 - accuracy: 0.0765WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 216 batches). You may need to use the repeat() function when building your dataset.\n",
      "864/864 [==============================] - 27s 29ms/step - loss: 3.5186 - accuracy: 0.0764 - val_loss: 3.3532 - val_accuracy: 0.2037\n",
      "Epoch 2/80\n",
      "864/864 [==============================] - 24s 28ms/step - loss: 3.1615 - accuracy: 0.1759\n",
      "Epoch 3/80\n",
      "864/864 [==============================] - 26s 29ms/step - loss: 2.5957 - accuracy: 0.3495\n",
      "Epoch 4/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 2.0505 - accuracy: 0.4745\n",
      "Epoch 5/80\n",
      "864/864 [==============================] - 21s 24ms/step - loss: 1.6924 - accuracy: 0.5475\n",
      "Epoch 6/80\n",
      "864/864 [==============================] - 26s 30ms/step - loss: 1.4126 - accuracy: 0.59840s - loss: 1.4093 \n",
      "Epoch 7/80\n",
      "864/864 [==============================] - 23s 26ms/step - loss: 1.2383 - accuracy: 0.6551\n",
      "Epoch 8/80\n",
      "864/864 [==============================] - 22s 25ms/step - loss: 1.0954 - accuracy: 0.6979\n",
      "Epoch 9/80\n",
      "864/864 [==============================] - 23s 27ms/step - loss: 0.9969 - accuracy: 0.7106\n",
      "Epoch 10/80\n",
      "864/864 [==============================] - 22s 26ms/step - loss: 0.8669 - accuracy: 0.7558\n",
      "Epoch 11/80\n",
      "864/864 [==============================] - 27s 31ms/step - loss: 0.7974 - accuracy: 0.7604\n",
      "Epoch 12/80\n",
      "864/864 [==============================] - 25s 29ms/step - loss: 0.7249 - accuracy: 0.7928\n",
      "Epoch 13/80\n",
      "864/864 [==============================] - 22s 25ms/step - loss: 0.6785 - accuracy: 0.8044\n",
      "Epoch 14/80\n",
      "864/864 [==============================] - 20s 24ms/step - loss: 0.6382 - accuracy: 0.8171\n",
      "Epoch 15/80\n",
      "864/864 [==============================] - 22s 26ms/step - loss: 0.5864 - accuracy: 0.8403\n",
      "Epoch 16/80\n",
      "864/864 [==============================] - 33s 38ms/step - loss: 0.5247 - accuracy: 0.8495\n",
      "Epoch 17/80\n",
      "864/864 [==============================] - 23s 27ms/step - loss: 0.4912 - accuracy: 0.8634\n",
      "Epoch 18/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.4899 - accuracy: 0.8495\n",
      "Epoch 19/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.4730 - accuracy: 0.8681\n",
      "Epoch 20/80\n",
      "864/864 [==============================] - 21s 24ms/step - loss: 0.4467 - accuracy: 0.8611\n",
      "Epoch 21/80\n",
      "864/864 [==============================] - 23s 27ms/step - loss: 0.3771 - accuracy: 0.8900\n",
      "Epoch 22/80\n",
      "864/864 [==============================] - 22s 25ms/step - loss: 0.3563 - accuracy: 0.8958\n",
      "Epoch 23/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.3273 - accuracy: 0.9086\n",
      "Epoch 24/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.3508 - accuracy: 0.8935\n",
      "Epoch 25/80\n",
      "864/864 [==============================] - 21s 24ms/step - loss: 0.3186 - accuracy: 0.9120\n",
      "Epoch 26/80\n",
      "864/864 [==============================] - 21s 24ms/step - loss: 0.3047 - accuracy: 0.9051\n",
      "Epoch 27/80\n",
      "864/864 [==============================] - 23s 27ms/step - loss: 0.2698 - accuracy: 0.9282\n",
      "Epoch 28/80\n",
      "864/864 [==============================] - 20s 24ms/step - loss: 0.2745 - accuracy: 0.9201\n",
      "Epoch 29/80\n",
      "864/864 [==============================] - 21s 24ms/step - loss: 0.2689 - accuracy: 0.9190\n",
      "Epoch 30/80\n",
      "864/864 [==============================] - 24s 27ms/step - loss: 0.2404 - accuracy: 0.9329\n",
      "Epoch 31/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.2461 - accuracy: 0.9329\n",
      "Epoch 32/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.2220 - accuracy: 0.93404s - loss: 0.2 - ETA: 4s - loss: 0.2135 - accuracy: 0. - ETA: 4s - loss: 0 - ETA: 3s - loss: 0.2118 - accuracy - ETA: 3s - los - ETA: 2s - loss: 0.2 - ETA: 1s - loss: 0.2215 \n",
      "Epoch 33/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.1992 - accuracy: 0.94560s - loss: 0.193\n",
      "Epoch 34/80\n",
      "864/864 [==============================] - 19s 22ms/step - loss: 0.2210 - accuracy: 0.9421\n",
      "Epoch 35/80\n",
      "864/864 [==============================] - 19s 22ms/step - loss: 0.1949 - accuracy: 0.9479\n",
      "Epoch 36/80\n",
      "864/864 [==============================] - 19s 22ms/step - loss: 0.1991 - accuracy: 0.9444\n",
      "Epoch 37/80\n",
      "864/864 [==============================] - 22s 25ms/step - loss: 0.1850 - accuracy: 0.9514\n",
      "Epoch 38/80\n",
      "864/864 [==============================] - 21s 25ms/step - loss: 0.1846 - accuracy: 0.9421: 19s -  - ETA: 5s - loss: 0.1927 - accu - ETA: 5s - ETA\n",
      "Epoch 39/80\n",
      "864/864 [==============================] - 28s 33ms/step - loss: 0.1788 - accuracy: 0.9560\n",
      "Epoch 40/80\n",
      "864/864 [==============================] - 21s 24ms/step - loss: 0.1462 - accuracy: 0.9606\n",
      "Epoch 41/80\n",
      "864/864 [==============================] - 21s 24ms/step - loss: 0.1436 - accuracy: 0.9618\n",
      "Epoch 42/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.1319 - accuracy: 0.9583\n",
      "Epoch 43/80\n",
      "864/864 [==============================] - 19s 22ms/step - loss: 0.1537 - accuracy: 0.9502\n",
      "Epoch 44/80\n",
      "864/864 [==============================] - 22s 25ms/step - loss: 0.1565 - accuracy: 0.9468\n",
      "Epoch 45/80\n",
      "864/864 [==============================] - 24s 28ms/step - loss: 0.1395 - accuracy: 0.9630\n",
      "Epoch 46/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.1225 - accuracy: 0.9664\n",
      "Epoch 47/80\n",
      "864/864 [==============================] - 20s 24ms/step - loss: 0.1354 - accuracy: 0.9583\n",
      "Epoch 48/80\n",
      "864/864 [==============================] - 22s 26ms/step - loss: 0.1289 - accuracy: 0.9664\n",
      "Epoch 49/80\n",
      "864/864 [==============================] - 23s 27ms/step - loss: 0.1174 - accuracy: 0.96640s -\n",
      "Epoch 50/80\n",
      "864/864 [==============================] - 24s 28ms/step - loss: 0.1251 - accuracy: 0.96181s - loss: 0.1215 - ac - ETA: 1s - loss:\n",
      "Epoch 51/80\n",
      "864/864 [==============================] - 19s 22ms/step - loss: 0.1194 - accuracy: 0.9630\n",
      "Epoch 52/80\n",
      "864/864 [==============================] - 19s 22ms/step - loss: 0.0983 - accuracy: 0.9734\n",
      "Epoch 53/80\n",
      "864/864 [==============================] - 19s 22ms/step - loss: 0.1017 - accuracy: 0.9699\n",
      "Epoch 54/80\n",
      "864/864 [==============================] - 19s 22ms/step - loss: 0.1053 - accuracy: 0.9676\n",
      "Epoch 55/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.1080 - accuracy: 0.96884s - loss: 0.1\n",
      "Epoch 56/80\n",
      "864/864 [==============================] - 19s 22ms/step - loss: 0.0958 - accuracy: 0.9734\n",
      "Epoch 57/80\n",
      "864/864 [==============================] - 19s 21ms/step - loss: 0.1011 - accuracy: 0.9711\n",
      "Epoch 58/80\n",
      "864/864 [==============================] - 19s 22ms/step - loss: 0.1154 - accuracy: 0.96640s - loss: 0.1\n",
      "Epoch 59/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.1002 - accuracy: 0.9664\n",
      "Epoch 60/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.0914 - accuracy: 0.9780\n",
      "Epoch 61/80\n",
      "864/864 [==============================] - 21s 24ms/step - loss: 0.0881 - accuracy: 0.97340s -\n",
      "Epoch 62/80\n",
      "864/864 [==============================] - 21s 24ms/step - loss: 0.0931 - accuracy: 0.9688\n",
      "Epoch 63/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.0759 - accuracy: 0.9780\n",
      "Epoch 64/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.0855 - accuracy: 0.9711\n",
      "Epoch 65/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.0762 - accuracy: 0.9803\n",
      "Epoch 66/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.0736 - accuracy: 0.9838\n",
      "Epoch 67/80\n",
      "864/864 [==============================] - 21s 25ms/step - loss: 0.0919 - accuracy: 0.9722\n",
      "Epoch 68/80\n",
      "864/864 [==============================] - 19s 22ms/step - loss: 0.0821 - accuracy: 0.9757\n",
      "Epoch 69/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.0779 - accuracy: 0.9757\n",
      "Epoch 70/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.0732 - accuracy: 0.98152s - los - E\n",
      "Epoch 71/80\n",
      "864/864 [==============================] - 21s 24ms/step - loss: 0.0712 - accuracy: 0.98152s - loss: 0.0 - ETA: 0s - loss: 0.0723 - ac\n",
      "Epoch 72/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 21s 24ms/step - loss: 0.0881 - accuracy: 0.9734\n",
      "Epoch 73/80\n",
      "864/864 [==============================] - 20s 24ms/step - loss: 0.0573 - accuracy: 0.9769\n",
      "Epoch 74/80\n",
      "864/864 [==============================] - 20s 24ms/step - loss: 0.0704 - accuracy: 0.98032s - loss: 0.0712 -  - ETA: 2s - loss: 0.0698 - accuracy: 0.98 - ETA: 2s - l - ETA: 1s - loss: 0.0680 - accuracy: 0. - ETA: \n",
      "Epoch 75/80\n",
      "864/864 [==============================] - 20s 23ms/step - loss: 0.0815 - accuracy: 0.9711\n",
      "Epoch 76/80\n",
      "864/864 [==============================] - 23s 27ms/step - loss: 0.0640 - accuracy: 0.9850\n",
      "Epoch 77/80\n",
      "864/864 [==============================] - 24s 28ms/step - loss: 0.0639 - accuracy: 0.9792\n",
      "Epoch 78/80\n",
      "864/864 [==============================] - 26s 30ms/step - loss: 0.0604 - accuracy: 0.9826\n",
      "Epoch 79/80\n",
      "864/864 [==============================] - 21s 25ms/step - loss: 0.0663 - accuracy: 0.9815\n",
      "Epoch 80/80\n",
      "864/864 [==============================] - 19s 22ms/step - loss: 0.0572 - accuracy: 0.9769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19944f3a670>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = train_generator.samples // batch_size,\n",
    "      validation_data = validation_generator, \n",
    "      validation_steps = validation_generator.samples // batch_size,\n",
    "      epochs = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "818a3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Task-8_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
